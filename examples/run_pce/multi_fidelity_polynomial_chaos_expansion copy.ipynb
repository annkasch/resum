{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "np.random.seed(42)\n",
    "import os\n",
    "from resum.polynomial_chaos_expansion import PCEMultiFidelityModel\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../binary-black-hole/settings.yaml\", \"r\") as f:\n",
    "    config_file = yaml.safe_load(f)\n",
    "\n",
    "version       = config_file[\"path_settings\"][\"version\"]\n",
    "path_out_cnp  = config_file[\"path_settings\"][\"path_out_cnp\"]\n",
    "path_out_pce = config_file[\"path_settings\"][\"path_out_pce\"]\n",
    "file_in=f'{path_out_cnp}/cnp_{version}_output.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(path_out_pce):\n",
    "   os.makedirs(path_out_pce)\n",
    "\n",
    "# Set parameter name/x_labels -> needs to be consistent with data input file\n",
    "x_labels        = config_file[\"simulation_settings\"][\"theta_headers\"]\n",
    "y_label_cnp     = 'y_cnp'\n",
    "y_err_label_cnp = 'y_cnp_err'\n",
    "y_label_sim     = 'y_raw'\n",
    "\n",
    "# Set parameter boundaries\n",
    "xmin = config_file[\"simulation_settings\"][\"theta_min\"]\n",
    "xmax = config_file[\"simulation_settings\"][\"theta_max\"]\n",
    "x_fixed = config_file[\"simulation_settings\"][\"theta_fixed\"]\n",
    "parameters={}\n",
    "for i,x in enumerate(x_labels):\n",
    "   parameters[x]=[xmin[i],xmax[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LF_cnp_noise=np.mean(data.loc[(data['fidelity']==0.) & (data['iteration']==0)][y_err_label_cnp].to_numpy())\n",
    "HF_cnp_noise=np.mean(data.loc[(data['fidelity']==1.) & (data['iteration']==0)][y_err_label_cnp].to_numpy())\n",
    "\n",
    "x_train_hf = data.loc[(data['fidelity']==1.) & (data['iteration']==0)][x_labels].to_numpy()\n",
    "y_train_hf = data.loc[(data['fidelity']==1.) & (data['iteration']==0)][y_label_sim].to_numpy()\n",
    "\n",
    "x_train_mf = data.loc[(data['fidelity']==1.) & (data['iteration']==0)][x_labels].to_numpy()\n",
    "y_train_mf = data.loc[(data['fidelity']==1.) & (data['iteration']==0)][ y_label_cnp].to_numpy()\n",
    "\n",
    "x_train_lf_sim = data.loc[(data['fidelity']==0.) & (data['iteration']==0)][x_labels].to_numpy()\n",
    "y_train_lf_sim = data.loc[(data['fidelity']==0.) & (data['iteration']==0)][ y_label_sim].to_numpy()\n",
    "\n",
    "x_train_lf = data.loc[(data['fidelity']==0.) & (data['iteration']==0)][x_labels].to_numpy()\n",
    "y_train_lf = data.loc[(data['fidelity']==0.) & (data['iteration']==0)][ y_label_cnp].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "trainings_data = {\"lf\": [x_train_lf,y_train_lf], \n",
    "#    \"mf\": [x_train_mf, y_train_mf], \n",
    "#    \"hf\": [x_train_hf,y_train_hf]\n",
    "}\n",
    "\n",
    "priors = {\n",
    "    \"lf\": {\"sigma_coeffs\": 0.5, \"sigma\": 0.01},\n",
    "#    \"mf\": {\"sigma_rho\": 0.05, \"sigma_coeffs_delta\": 0.05, \"sigma\": 0.01},\n",
    "#    \"hf\": {\"sigma_rho\": 0.05, \"sigma_coeffs_delta\": 0.05, \"sigma\": 0.01}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(degree):\n",
    "    # Initialize the multi-fidelity model\n",
    "    multi_fidelity_model = None\n",
    "    multi_fidelity_model = PCEMultiFidelityModel(trainings_data, priors, degree=degree)\n",
    "    multi_fidelity_model.build_model()\n",
    "    multi_fidelity_model.sanity_check_of_basis()\n",
    "    with multi_fidelity_model.model:\n",
    "        trace = pm.sample(draws=700, tune=100, chains=1, target_accept=0.99, init=\"adapt_diag\",cores=1, return_inferencedata=True, log_likelihood=True, progressbar=True)\n",
    "    az.plot_trace(trace)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    az.plot_energy(trace)  # reveals E-BFMI problems\n",
    "    az.plot_forest(trace, var_names=[\"sigma_lf\", \"coeffs_lf\"])\n",
    "    multi_fidelity_model.add_log_likelihood_manually(trace)\n",
    "    return multi_fidelity_model, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1, trace_1 = run_model(degree=1)\n",
    "model_2, trace_2 = run_model(degree=2)\n",
    "model_3, trace_3 = run_model(degree=3)\n",
    "model_6, trace_6 = run_model(degree=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = az.compare({\"deg1\": trace_1, \"deg2\": trace_2, \"deg3\": trace_3, \"deg6\": trace_6}, ic=\"loo\")\n",
    "print(comparison)\n",
    "az.plot_compare(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
